{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0091c39",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cargo las librerias y los archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61f9a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67d1e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ruta = '/Users/bita/Downloads/vitality/Data_Entry_2017.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93532bec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(ruta)\n",
    "all_image_paths = {os.path.basename(x): x for x in glob(os.path.join('/Users/bita/Downloads/vitality/images/*.png'))}\n",
    "df['path'] = df['Image Index'].map(all_image_paths.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1df10c",
   "metadata": {},
   "source": [
    "# Selecciono solo las filas que tienen su imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7997dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['path'].notnull()\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['path', 'Finding Labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d94ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "paths = df['path'].values\n",
    "labels = df['Finding Labels'].str.split('|').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear listas para almacenar las imágenes y las etiquetas procesadas\n",
    "images = []\n",
    "processed_labels = []\n",
    "\n",
    "# Recorrer las rutas de las imágenes\n",
    "for i,path in enumerate(list(paths)):\n",
    "    # Cargar la imagen usando OpenCV\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    # Preprocesar la imagen (ajustar tamaño, normalizar, etc.)\n",
    "    # Aquí puedes aplicar cualquier preprocesamiento específico que necesites\n",
    "    # Por ejemplo, puedes redimensionar la imagen a un tamaño específico:\n",
    "    image = cv2.resize(image, (224, 224), )\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  # Normalizar los valores de píxel\n",
    "    \n",
    "    # Agregar la imagen y las etiquetas procesadas a las listas\n",
    "    images.append(image)\n",
    "    processed_labels.append(encoded_labels[i])\n",
    "\n",
    "# Convertir las listas en arrays de NumPy\n",
    "images = np.array(images)\n",
    "processed_labels = np.array(processed_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34a773",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Tamaño de las imágenes\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Crear el modelo de CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Agregar capas convolucionales y de pooling\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_size))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Aplanar los mapas de características\n",
    "model.add(Flatten())\n",
    "\n",
    "# Agregar capas densas para la clasificación\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Imprimir un resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaba2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Tamaño de las imágenes\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, processed_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Crear un nuevo modelo de Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# Agregar el modelo pre-entrenado como capa\n",
    "model.add(vgg16)\n",
    "\n",
    "# Agregar capas adicionales para la clasificación\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "# Compilar y entrenar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009b795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf3f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
